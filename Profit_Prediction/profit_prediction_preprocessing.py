# -*- coding: utf-8 -*-
"""profit_prediction_preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CwdtS4LmmqzPFw983aPP2DMZ-IZM7pzU
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import NearestNeighbors
import random
from typing import List

data = pd.read_csv('/content/profit_templete_dataset.csv')

data.shape

data.tail(50)

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import NearestNeighbors
import random
from typing import List

class DatasetAugmenter:
    def __init__(self, df: pd.DataFrame, target_rows: int = 500):
        self.df = df.copy()
        self.target_rows = target_rows
        self.numeric_columns = df.select_dtypes(include=[np.number]).columns.tolist()
        self.categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()

    def add_noise(self, df: pd.DataFrame, noise_factor: float = 0.1) -> pd.DataFrame:
        augmented_df = df.copy()
        for col in self.numeric_columns:
            std_dev = augmented_df[col].std()
            if std_dev == 0:
                std_dev = 1e-4
            noise = np.random.normal(0, std_dev * noise_factor, len(augmented_df))
            augmented_df[col] = augmented_df[col] + noise
        return augmented_df

    def interpolate_rows(self, df: pd.DataFrame, n_samples: int) -> pd.DataFrame:
        augmented_rows = []
        non_zero_df = df[(df[self.numeric_columns] != 0).any(axis=1)]
        for _ in range(n_samples):
            if len(non_zero_df) < 2:
                break
            row1, row2 = non_zero_df.sample(2).to_dict('records')
            new_row = {}
            alpha = random.random()
            for col in df.columns:
                if col in self.numeric_columns:
                    new_row[col] = alpha * row1[col] + (1 - alpha) * row2[col]
                else:
                    new_row[col] = random.choice([row1[col], row2[col]])
            augmented_rows.append(new_row)
        return pd.DataFrame(augmented_rows)


    def smote_like_augmentation(self, df: pd.DataFrame, n_samples: int) -> pd.DataFrame:
        if not self.numeric_columns:
            return self.interpolate_rows(df, n_samples)
        non_zero_df = df[(df[self.numeric_columns] != 0).any(axis=1)].reset_index(drop=True)
        if len(non_zero_df) < 2:
            return self.interpolate_rows(df, n_samples)
        numeric_df = non_zero_df[self.numeric_columns]
        scaler = StandardScaler()
        scaled_data = scaler.fit_transform(numeric_df)
        k = min(5, len(non_zero_df) - 1)
        nbrs = NearestNeighbors(n_neighbors=k + 1).fit(scaled_data)
        augmented_rows = []
        for _ in range(n_samples):
            idx = random.randint(0, len(non_zero_df) - 1)
            distances, indices = nbrs.kneighbors([scaled_data[idx]])
            neighbor_idx = random.choice(indices[0][1:])
            row1 = non_zero_df.iloc[idx]
            row2 = non_zero_df.iloc[neighbor_idx]
            alpha = random.random()
            new_row = {}
            for col in df.columns:
                if col in self.numeric_columns:
                    new_row[col] = alpha * row1[col] + (1 - alpha) * row2[col]
                else:
                    new_row[col] = random.choice([row1[col], row2[col]])
            augmented_rows.append(new_row)
        return pd.DataFrame(augmented_rows)

    def bootstrap_sampling(self, df: pd.DataFrame, n_samples: int) -> pd.DataFrame:
        sampled_df = df.sample(n=n_samples, replace=True)
        return self.add_noise(sampled_df, noise_factor=0.05)

    def augment_dataset(self, methods: List[str] = None) -> pd.DataFrame:
        if methods is None:
            methods = ['noise', 'interpolate', 'smote', 'bootstrap']
        current_rows = len(self.df)
        rows_needed = self.target_rows - current_rows
        if rows_needed <= 0:
            print(f"Dataset already has {current_rows} rows, which is >= target of {self.target_rows}")
            return self.df
        print(f"Augmenting dataset from {current_rows} to {self.target_rows} rows")
        augmented_df = self.df.copy()
        rows_per_method = rows_needed // len(methods)
        remaining_rows = rows_needed % len(methods)
        for i, method in enumerate(methods):
            method_rows = rows_per_method + (1 if i < remaining_rows else 0)
            if method_rows == 0:
                continue
            if method == 'noise':
                sampled = self.df.sample(n=method_rows, replace=True)
                new_rows = self.add_noise(sampled)
            elif method == 'interpolate':
                new_rows = self.interpolate_rows(self.df, method_rows)
            elif method == 'smote':
                new_rows = self.smote_like_augmentation(self.df, method_rows)
            elif method == 'bootstrap':
                new_rows = self.bootstrap_sampling(self.df, method_rows)
            else:
                continue
            augmented_df = pd.concat([augmented_df, new_rows], ignore_index=True)
        print(f"Final dataset size: {len(augmented_df)} rows")
        return augmented_df


# ========= MAIN FUNCTION ========= #
def augment_csv(input_file: str, output_file: str, target_rows: int = 500):
    df = pd.read_csv(input_file)
    print(f"\nOriginal dataset shape: {df.shape}")
    augmenter = DatasetAugmenter(df, target_rows=target_rows)
    augmented_df = augmenter.augment_dataset()
    augmented_df.to_csv(output_file, index=False)
    print(f"\nAugmented dataset saved to: {output_file}")
    return augmented_df


# ========= EXECUTION ========== #
if __name__ == "__main__":
    input_csv = "/content/profit_templete_dataset.csv"  # from your uploaded file
    output_csv = "profit_augmented_dataset.csv"

    try:
        augmented_df = augment_csv(input_csv, output_csv, target_rows=500)
        print("\n" + "="*50)
        print("AUGMENTATION SUMMARY")
        print("="*50)
        print(f"Original rows: 150")
        print(f"Final rows: {len(augmented_df)}")
        print(f"Rows added: {len(augmented_df) - 150}")
        print("\nSample rows from result:")
        print(augmented_df.head())
    except Exception as e:
        print(f"An error occurred: {e}")

df = pd.read_csv('/content/profit_augmented_dataset.csv')

df.shape

df.tail(50)

df.info()

