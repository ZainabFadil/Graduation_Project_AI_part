# -*- coding: utf-8 -*-
"""success_prediction_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bvV2psXwDuqNr5Bn73v0I1Im5fA53TwP
"""

import pandas as pd

# تحميل البيانات
df = pd.read_csv("cleaned_augmented_success_prediction_dataset.csv")

# حذف الصفوف اللي فيها missing في العمود الهدف
df_clean = df.dropna(subset=["is_successful"]).copy()

"""***Feature Engineering***"""

# حساب عمر الشركة بدل سنة التأسيس
current_year = 2025
df_clean["startup_age"] = current_year - df_clean["founded_year"]

# حذف العمود القديم
df_clean.drop("founded_year", axis=1, inplace=True)

# الأعمدة الاسمية اللي هنعملها Label Encoding
from sklearn.preprocessing import LabelEncoder

categorical_cols = ["city", "industry", "startup_stage",
                    "market_competition_level", "num_direct_competitors",
                    "market_need_level"]

label_encoders = {}

for col in categorical_cols:
    le = LabelEncoder()
    df_clean[col] = le.fit_transform(df_clean[col])
    label_encoders[col] = le

"""***Data Splitting (X AND Y)***"""

# فصل البيانات
X = df_clean.drop("is_successful", axis=1)
y = df_clean["is_successful"]

"""***Scaling***"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

"""***Data Splitting (Train / Test)***"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42)

"""***Model Building***"""

pip install xgboost

import time
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from xgboost import XGBClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# تعريف الموديلات
models = {
    "RandomForest": RandomForestClassifier(random_state=42),
    "LogisticRegression": LogisticRegression(max_iter=1000, random_state=42),
    "SVM": SVC(probability=True, random_state=42),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),
    "KNN": KNeighborsClassifier()
}

# تخزين النتائج
results = {}

# تجربة وتقييم كل موديل
for name, model in models.items():
    print(f"\n====== {name} ======")

    start_time = time.time()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    end_time = time.time()

    accuracy = accuracy_score(y_test, y_pred)
    f1 = classification_report(y_test, y_pred, output_dict=True)['weighted avg']['f1-score']
    conf = confusion_matrix(y_test, y_pred)

    print(f"Accuracy: {accuracy:.4f}")
    print(f"F1 Score: {f1:.4f}")
    print("Confusion Matrix:")
    print(conf)
    print(f"Time taken: {end_time - start_time:.2f} seconds")

    # تخزين النتائج لاستخدام لاحق
    results[name] = {
        "Accuracy": accuracy,
        "F1 Score": f1,
        "Time": end_time - start_time,
        "Confusion Matrix": conf
    }

"""***Use Logistic regression model***

***calculate Training Accuracy and Testing Accuracy***
"""

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import joblib

# تدريب الموديل
logreg = LogisticRegression(max_iter=1000, random_state=42)
logreg.fit(X_train, y_train)

# حساب Training Accuracy
train_preds = logreg.predict(X_train)
train_acc = accuracy_score(y_train, train_preds)
print("Training Accuracy:", train_acc)

# حساب Testing Accuracy
test_preds = logreg.predict(X_test)
test_acc = accuracy_score(y_test, test_preds)
print("Testing Accuracy:", test_acc)

"""***Save model as PKL***"""

# حفظ الموديل
joblib.dump(logreg, "logistic_model.pkl")

import joblib

# 1. حفظ الموديل
joblib.dump(logreg, "logistic_model.pkl")

# 2. حفظ الـ Scaler
joblib.dump(scaler, "scaler.pkl")

# 3. حفظ الـ Label Encoders (لو كنتِ استخدمتيهم في Feature Engineering)
joblib.dump(label_encoders, "label_encoders.pkl")

print("✅ تم حفظ الموديل وكل الأدوات بنجاح!")